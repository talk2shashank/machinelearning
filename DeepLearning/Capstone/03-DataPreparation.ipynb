{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imresize\n",
    "%matplotlib inline\n",
    "\n",
    "pixel_depth = 255.0\n",
    "screen_width = 32\n",
    "screen_height = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('svhn.pickle', 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "except Exception as e:\n",
    "    print('Unable to process data from dataset.pickle', ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_image(image_file, path='train/', **box):\n",
    "    image_data = np.average(ndimage.imread(path+image_file), axis=2)\n",
    "    if box['minTop'] <= 0: box['minTop'] = 0\n",
    "    if box['minLeft'] <= 0: box['minLeft'] = 0\n",
    "    image_data = image_data[box['minTop']:box['maxTopHeight'], box['minLeft']:box['maxLeftWidth']]\n",
    "    image_data = imresize(image_data, (32,32))\n",
    "    image_data = (image_data.astype(float) - pixel_depth / 2) / pixel_depth\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'elapsed out of ', 33402, 'for: ', 'train')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 'elapsed out of ', 33402, 'for: ', 'train')\n",
      "(10000, 'elapsed out of ', 33402, 'for: ', 'train')\n",
      "(15000, 'elapsed out of ', 33402, 'for: ', 'train')\n",
      "(20000, 'elapsed out of ', 33402, 'for: ', 'train')\n",
      "(25000, 'elapsed out of ', 33402, 'for: ', 'train')\n",
      "(30000, 'elapsed out of ', 33402, 'for: ', 'train')\n",
      "(0, 'elapsed out of ', 13068, 'for: ', 'test')\n",
      "(5000, 'elapsed out of ', 13068, 'for: ', 'test')\n",
      "(10000, 'elapsed out of ', 13068, 'for: ', 'test')\n",
      "(0, 'elapsed out of ', 2000, 'for: ', 'valid')\n",
      "(0, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(5000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(10000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(15000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(20000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(25000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(30000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(35000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(40000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(45000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(50000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(55000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(60000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(65000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(70000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(75000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(80000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(85000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(90000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(95000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(100000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(105000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(110000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(115000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(120000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(125000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(130000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(135000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(140000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(145000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(150000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(155000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(160000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(165000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(170000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(175000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(180000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(185000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(190000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(195000, 'elapsed out of ', 202353, 'for: ', 'extra')\n",
      "(200000, 'elapsed out of ', 202353, 'for: ', 'extra')\n"
     ]
    }
   ],
   "source": [
    "def load_images(dataset, struct):\n",
    "    images = dataset[struct]['images']\n",
    "    tops = dataset[struct]['tops']\n",
    "    widths = dataset[struct]['widths']\n",
    "    heights = dataset[struct]['heights']\n",
    "    lefts = dataset[struct]['lefts']\n",
    "    data = np.ndarray(shape=(images.shape[0], 32, 32), dtype=np.float32)\n",
    "        \n",
    "    for i in range(data.shape[0]):\n",
    "        if (i % 5000 == 0):\n",
    "            print(i, \"elapsed out of \", data.shape[0], \"for: \", struct)\n",
    "        try:\n",
    "            if struct == 'valid':\n",
    "                path = 'extra/'\n",
    "            else:\n",
    "                path = struct + '/'\n",
    "            chrCount = dataset[struct]['labels'][i][dataset[struct]['labels'][i] > -1].shape[0]\n",
    "            topHeights = np.array([tops[i][:chrCount], heights[i][:chrCount]])\n",
    "            leftWidths = np.array([lefts[i][:chrCount], widths[i][:chrCount]])\n",
    "            image = load_image(images[i], path, **{\n",
    "                    \"minTop\": min(topHeights[0, :]),\n",
    "                    \"minLeft\": min(leftWidths[1, :]),\n",
    "                    \"maxTopHeight\": topHeights.sum(axis=0).max(),\n",
    "                    \"maxLeftWidth\": leftWidths.sum(axis=0).max()\n",
    "            })\n",
    "            data[i, :, :] = image\n",
    "        except Exception, e:\n",
    "            img = np.average(ndimage.imread(path+images[i]), axis=2)\n",
    "            print( i, chrCount,img.shape, {\n",
    "                \"minTop\": min(topHeights[0, :]),\n",
    "                \"minLeft\": min(leftWidths[1, :]),\n",
    "                \"maxTopHeight\": topHeights.sum(axis=0).max(),\n",
    "                \"maxLeftWidth\": leftWidths.sum(axis=0).max(),\n",
    "                \"lefts\": lefts[i],\n",
    "                \"widths\": widths[i],\n",
    "                \"message\": e.message\n",
    "            })\n",
    "            return\n",
    "    return data\n",
    "\n",
    "trX = load_images(dataset, 'train')\n",
    "teX = load_images(dataset, 'test')\n",
    "vaX = load_images(dataset, 'valid')\n",
    "exX = load_images(dataset, 'extra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trY = dataset['train']['labels']\n",
    "teY = dataset['test']['labels']\n",
    "vaY = dataset['valid']['labels']\n",
    "exY = dataset['extra']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open( 'tensorflow_data.pickle', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'train': {'data': trX, 'label': trY},\n",
    "            'test': {'data': teX, 'label': teY},\n",
    "            'valid': {'data': vaX, 'label': vaY},\n",
    "            'extra': {'data': exX, 'label': exY}\n",
    "        }, f, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to',  struct + '.pickle', ':', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
